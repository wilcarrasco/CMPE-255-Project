{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Individual Household Electric Power Consumption and Future Consumption Regression Analysis.\n",
    "\n",
    "Our group proposes to use the Individual household electric power consumption data set to look for power consumption trends over time. We plan on clustering the data using descriptive methods to discover patterns and trends. Applying predictive methods such as regression we plan to predict future power consumption.\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and clean the data\n",
    "Process the data by reading each line, removing the column header information and stripping the semicolon seperators. Then convert the date and time stamps to numeric values and merge the two to have a dataset with all numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_ratio(time_stamp):\n",
    "    time = datetime.strptime(time_stamp, '%d/%m/%Y %H:%M:%S')\n",
    "    start = datetime(year=time.year, month=1, day=1)\n",
    "    end = datetime(year=time.year+1, month=1, day=1)\n",
    "    return (time - start).total_seconds()/(end - start).total_seconds()\n",
    "\n",
    "def minutes_from_start(time_stamp, start_stamp):\n",
    "    time = datetime.strptime(time_stamp, '%d/%m/%Y %H:%M:%S')\n",
    "    start = datetime.strptime(start_stamp, '%d/%m/%Y %H:%M:%S')\n",
    "    return (time - start).total_seconds()/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data from text document\n",
    "with open('household_power_consumption.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "# Remove the '?' uncaptured data if detected\n",
    "data_raw_reduced = [line for line in lines if '?' not in line] \n",
    "\n",
    "# strip the header information and remove semicolons     \n",
    "data_raw = [l.split(';') for l in data_raw_reduced][1::]\n",
    "\n",
    "# Convert date and time to a numeric value/ratio\n",
    "time_ratios = [time_to_ratio(f'{t[0]} {t[1]}') for t in data_raw]\n",
    "\n",
    "# merge time with raw data removing time stamp strings and replacing with ratios\n",
    "data_time_raw = [[t, float(gap), float(grp), float(v), float(gi), float(s1), float(s2), float(s3)] for (_, _, gap, grp, v, gi, s1, s2, s3), (t) in zip(data_raw, time_ratios)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify columns/rows/data are as expected.\n",
    "print(\"Number of rows: {}\".format(len(data_time_raw)))\n",
    "print(\"Number of columns: {}\".format(len(data_time_raw[0])))\n",
    "print(data_time_raw[:5])\n",
    "\n",
    "# Convert to np array for better processing.\n",
    "data_time_np = np.array(data_time_raw, dtype=float)\n",
    "print(\"Number of rows: {}\".format(data_time_np.shape[0]))\n",
    "print(\"Number of columns: {}\".format(data_time_np.shape[1]))\n",
    "print(data_time_np[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = f'{data_raw[0][0]} {data_raw[0][1]}' # the first time stamp\n",
    "time_from_start = [minutes_from_start(f'{t[0]} {t[1]}', start_time) for t in data_raw] # array of minutes from first time stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data_time_np)\n",
    "df_data\n",
    "df_data_2006_time = df_data[0][0:21992] \n",
    "df_data_2006_ap = df_data[1][0:21992]\n",
    "df_data_2007_time = df_data[0][21992:543661] \n",
    "df_data_2007_ap = df_data[1][21992:543661]\n",
    "df_data_2008_time = df_data[0][543661:1070566] \n",
    "df_data_2008_ap = df_data[1][543661:1070566] \n",
    "df_data_2009_time = df_data[0][1070566:1591886]\n",
    "df_data_2009_ap = df_data[1][1070566:1591886]\n",
    "df_data_2010_time = df_data[0][1591886:]\n",
    "df_data_2010_ap = df_data[1][1591886:]\n",
    "\n",
    "fig_combined=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(df_data_2006_time, df_data_2006_ap,'r--',\n",
    "        df_data_2007_time, df_data_2007_ap, 'b--',\n",
    "        df_data_2008_time, df_data_2008_ap, 'g--',\n",
    "        df_data_2009_time, df_data_2009_ap, 'c--',\n",
    "        df_data_2010_time, df_data_2010_ap, 'y--', )\n",
    "plt.xlabel('Date of Year')\n",
    "plt.ylabel('Active Power (kW)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_separate=plt.figure(figsize=(10,10), dpi= 100, facecolor='w', edgecolor='k')\n",
    "ax1 = plt.subplot(511)\n",
    "plt.plot(df_data_2006_time, df_data_2006_ap, 'r--')\n",
    "ax2 = plt.subplot(512,sharex=ax1)\n",
    "plt.plot(df_data_2007_time, df_data_2007_ap, 'b--')\n",
    "ax2 = plt.subplot(513,sharex=ax1,ylabel='Active Power(kW)')\n",
    "plt.plot(df_data_2008_time, df_data_2008_ap, 'g--')\n",
    "ax3 = plt.subplot(514,sharex=ax1)\n",
    "plt.plot(df_data_2009_time, df_data_2009_ap, 'c--')\n",
    "ax4 = plt.subplot(515,sharex=ax1,xlabel='Date of Year')\n",
    "plt.plot(df_data_2010_time, df_data_2010_ap, 'y--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Preprocessing Steps here ##\n",
    "global_power = data_time_np[:,1].copy() # global power - to check trends\n",
    "\n",
    "# Normalize by max value in a column\n",
    "for i in range(1, data_time_np.shape[1]):\n",
    "    data_time_np[:,i] *= (1.0/data_time_np[:,i].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(time_from_start, global_power)\n",
    "plt.figure(2)\n",
    "plt.plot(time_from_start, data_time_np[:,1])\n",
    "\n",
    "print(data_time_np[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Applying different Dimensionality reduction techniques, first to get a general visualization of the data, and second choosing a component factor that captures most of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced the dimensionality to be able to plot in 2D\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "data_time_np_vis = pca.fit_transform(data_time_np)\n",
    "\n",
    "# Verify Reduction\n",
    "print(data_time_np_vis.shape)\n",
    "\n",
    "# Visualize the Data\n",
    "plt.scatter(data_time_np_vis[:, 0], data_time_np_vis[:, 1], s=1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting proper n components for PCA based on explained variance \n",
    "pca_n = PCA().fit(data_time_np)\n",
    "plt.rcParams[\"figure.figsize\"] = (9,5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 9, step=1)\n",
    "y = np.cumsum(pca_n.explained_variance_ratio_)\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0, 11, step=1)) \n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.title('PCA')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% Cut-Off ', color = 'red', fontsize=12)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "data_time_np_reduced = pca.fit_transform(data_time_np)\n",
    "\n",
    "print(data_time_np_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Explained Variance from 4 components: {pca.explained_variance_ratio_.sum()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting proper n components for SVD based on explained variance \n",
    "svd_n = TruncatedSVD(n_components = 7).fit(data_time_np)\n",
    "plt.rcParams[\"figure.figsize\"] = (9,5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 8, step=1)\n",
    "y = np.cumsum(svd_n.explained_variance_ratio_)\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0, 8, step=1)) \n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.title('SVD')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% Cut-Off ', color = 'red', fontsize=12)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=5)\n",
    "data_time_np_reduced_svd = svd.fit_transform(data_time_np)\n",
    "\n",
    "print(data_time_np_reduced_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Explained Variance from 5 components: {svd.explained_variance_ratio_.sum()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8, figsize=(15,30))\n",
    "for i in range(8):\n",
    "    axs[i].plot(time_from_start, data_time_np[:,i])\n",
    "    axs[i].set_title(f'feature {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_np_reduced = np.delete(data_time_np, [1,2,3,4], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(4, figsize=(15,30))\n",
    "for i in range(4):\n",
    "    axs[i].plot(time_from_start, data_time_np_reduced[:,i])\n",
    "    axs[i].set_title(f'feature {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis\n",
    "\n",
    "To get a better representation of the data we will cluster the reduced data using PCA and try a selected approach to cluster against the three metering values and graphing the data in 3D"
   ]
  },
  {
   "source": [
    "## KMeans"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSSE(cluster):\n",
    "    '''\n",
    "    Retrieved the SSE of the passed in cluster\n",
    "    '''\n",
    "    kmeans = KMeans(\n",
    "    init=\"k-means++\",\n",
    "    n_clusters=1,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=None\n",
    "    )\n",
    "    kmeans.fit(cluster)\n",
    "    return kmeans.inertia_\n",
    "\n",
    "def biSectingKmeans(cluster, k=7, debug=False):\n",
    "    '''\n",
    "    Bisecting K-meanms Algorithmn \n",
    "    '''\n",
    "    \n",
    "    rows = cluster.shape[0]\n",
    "    c = []\n",
    "    cluster_list = []\n",
    "    for i in range(0, rows):\n",
    "        c.append(i)\n",
    "    \n",
    "    cluster_list.append(c)\n",
    "  \n",
    "    for x in range(k-1):\n",
    "        SEE = 0\n",
    "        index = 0\n",
    "        item = None\n",
    "        for lists in cluster_list:\n",
    "            x = getSSE(cluster[lists,:])\n",
    "            if debug:\n",
    "                print(x)\n",
    "            if (x > SEE):\n",
    "                SEE = x\n",
    "                item = index\n",
    "            index += 1\n",
    "        next_cluster = cluster_list.pop(item)\n",
    "    \n",
    "        kmeans = KMeans(\n",
    "        init=\"k-means++\",\n",
    "        n_clusters=2,\n",
    "        n_init=10,\n",
    "        max_iter=300,\n",
    "        random_state=None)\n",
    "\n",
    "        kmeans.fit(cluster[next_cluster,:])\n",
    "\n",
    "        c2 = []\n",
    "        c3 = []\n",
    "        for i in range(0, len(kmeans.labels_)):\n",
    "            if kmeans.labels_[i] == 0:\n",
    "                c2.append(next_cluster[i])\n",
    "            elif kmeans.labels_[i] == 1:\n",
    "                c3.append(next_cluster[i])\n",
    "            else:\n",
    "                print(\"ERROR BREAKING UP CLUSTER LIST!!!\")\n",
    "        cluster_list.append(c2)\n",
    "        cluster_list.append(c3)\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\n\")\n",
    "            print(c2[:20])\n",
    "            print(\"\\n\")\n",
    "            print(c3[:20])\n",
    "            print(\"*************************\")\n",
    "\n",
    "    return cluster_list\n",
    "\n",
    "def writeClusterFile(cluster, cluster_groups, file_name='Output.dat'):\n",
    "    rows = cluster.shape[0]\n",
    "    c = []\n",
    "    for i in range(0, rows):\n",
    "        c.append(-1)\n",
    "\n",
    "    num = 1\n",
    "    for lists in cluster_groups:\n",
    "        length = len(lists)\n",
    "        for i in range(length):\n",
    "            c[lists[i]] = num\n",
    "        num += 1\n",
    "\n",
    "    f = open(file_name, 'w')\n",
    "    for z in c:\n",
    "        f.write(str(z))\n",
    "        f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "def printSSE(cluster, cluster_groups):\n",
    "    cs_see = []\n",
    "\n",
    "    for lists in cluster_groups:\n",
    "        cs_see.append(getSSE(cluster[lists,:]))\n",
    "\n",
    "    cs_see.sort(reverse=True)\n",
    "    for lists in cs_see:\n",
    "        print(lists)\n",
    "\n",
    "    plt.plot(range(1, len(cs_see)+1), cs_see, 'r-o')\n",
    "    plt.xlabel(\"Clusters\")\n",
    "    plt.ylabel(\"SEE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bi-secting K-Means on cluster\n",
    "cluster_groups = biSectingKmeans(data_time_np_reduced, k=4, debug=True)\n",
    "print(len(cluster_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeClusterFile(data_time_np_reduced, cluster_groups)\n",
    "printSSE(data_time_np_reduced, cluster_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating figure\n",
    "fig = plt.figure(figsize = (10, 7))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    " \n",
    "# Creating plot\n",
    "ax.scatter3D(data_time_np[:, -3], data_time_np[:, -2], data_time_np[:, -1], color = \"green\")\n",
    "plt.title(\"Utility Cluster Group\")\n",
    " \n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_np_selected = data_time_np[:,5:8]\n",
    "print(data_time_np_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bi-secting K-Means on cluster\n",
    "cluster_groups_selected = biSectingKmeans(data_time_np_selected, k=6, debug=True)\n",
    "print(len(cluster_groups_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeClusterFile(data_time_np_selected, cluster_groups_selected, file_name='Output_selected.dat')\n",
    "printSSE(data_time_np_selected, cluster_groups_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating figure\n",
    "fig = plt.figure(figsize = (10, 7))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    " \n",
    "# Creating plot\n",
    "for l in cluster_groups_selected: \n",
    "    ax.scatter3D(data_time_np_selected[l, -3], data_time_np_selected[l, -2], data_time_np_selected[l, -1])\n",
    "    plt.title(\"Meter Cluster Group\")\n",
    "\n",
    "#ax.view_init(0, 0)\n",
    " \n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## OPTICS\n",
    "This clustering process was done in a separate notebook (clustering.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce data to X for continued analysis\n",
    "X = data_time_np.copy()[:,[5,6,7]]\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = X[::5].copy()\n",
    "\n",
    "X_red = X_red[~np.all(X_red == 0.0, axis=1)]\n",
    "print(X_red.shape[0])\n",
    "X_train, X_test = train_test_split(X_red, train_size=0.75, random_state=42)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X_train[:,0], X_train[:,1], X_train[:,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labels\n",
    "labels = np.load('minsamp200maxeps0.5minclust0.01eps0.05.npy')\n",
    "print(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for l in set(labels):\n",
    "    X_bylabel = X_train[labels == l]\n",
    "    ax.scatter3D(X_bylabel[:,0], X_bylabel[:,1], X_bylabel[:,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Cluster Association with Time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0502c2cd614d093a3be30031cbabda9e1b1b1c5d2fdc17ac0be9ebae842ffa0cd",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}